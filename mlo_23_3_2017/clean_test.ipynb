{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import basicLib.loadAndTest as orig\n",
    "import basicLib.featureUpdate as featUp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pandas import *\n",
    "from pylab import *\n",
    "from sklearn import preprocessing\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn import metrics\n",
    "import re\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import basicLib.modelRun as runms\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn import tree\n",
    "import time\n",
    "import clf2net\n",
    "import clf2netTest\n",
    "import clf2netTree\n",
    "from sklearn import ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'featureList' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-5a090e2288b5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0musers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0myRes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0morig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloadAndUpdateFeatures\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpathTrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpathTest\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpathTest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0morig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minitiateUsers\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0musers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mXtest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0morig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msortFeatures\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0musers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfeatureList\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'featureList' is not defined"
     ]
    }
   ],
   "source": [
    "pathTrain = '../input_clean/users_train_norm.csv'\n",
    "pathTest = '../input_clean/users_test_norm.csv'\n",
    "\n",
    "users, yRes = orig.loadAndUpdateFeatures(pathTrain, pathTest=pathTest)\n",
    "orig.initiateUsers(users)\n",
    "featureList = orig.featureList(usersCol=users.columns)\n",
    "Xtest = orig.sortFeatures(users,featureList.get())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pathTrain = '../input_clean/users_train_norm.csv'\n",
    "pathTest = '../input_clean/users_test_norm.csv'\n",
    "\n",
    "usersTrain = pd.read_csv(pathTrain)\n",
    "usersTest = pd.read_csv(pathTest)\n",
    "yRes = pd.DataFrame(usersTrain['country_destination'])\n",
    "yFeat = featUp.countriesFeature()\n",
    "yFeat.update(yRes)\n",
    "usersTrain = usersTrain.drop('country_destination',axis=1)\n",
    "users = pd.concat([usersTrain,usersTest],ignore_index=True)\n",
    "featureStruct=featUp.generateFeatureStruct()\n",
    "for feature in featureStruct:\n",
    "    feature.update(users)\n",
    "orig.initiateUsers(users)\n",
    "featureList = orig.featureList(usersCol=users.columns)\n",
    "Xtest = orig.sortFeatures(users,featureList.get())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xlabel = Xtest\n",
    "nonCategoryList=[]\n",
    "for feature, dtype in Xlabel.dtypes.iteritems():\n",
    "    if dtype.name != 'category':\n",
    "        nonCategoryList.append(feature)\n",
    "nonCategoryDF = Xlabel[nonCategoryList]\n",
    "Xlabel = Xlabel.drop(nonCategoryList, 1)\n",
    "\n",
    "labels = Xlabel.columns\n",
    "myLabels = {} # holds the encode labels with value between 0 and n-1\n",
    "n_values = [] # holds the length of each feature in bits ('gender' with 4 option will be 4 bits)\n",
    "X = []\n",
    "for label in Xlabel:\n",
    "    labelAttr = getattr(Xlabel, label)\n",
    "    myLabels[label] = preprocessing.LabelEncoder()\n",
    "    myLabels[label].fit(labelAttr)\n",
    "    if size(labelAttr.unique()) > 400:\n",
    "        raise TypeError('The feature:', label, 'is too big to handle as binary')\n",
    "    n_values.append(size(labelAttr.unique()))\n",
    "    #transform: turn options into 0 to n-1,  reshape+transpose: align the coulumn so it be easier to add them to the table \n",
    "    X.append(myLabels[label].transform(labelAttr).reshape(1,len(labelAttr)).transpose())\n",
    "\n",
    "#There is no category to change\n",
    "\n",
    "temp = np.array([]).reshape(len(X[0]),0)\n",
    "for i in range(len(X)):\n",
    "    temp = concatenate((temp,X[i]),axis=1)\n",
    "X = temp\n",
    "\n",
    "enc = preprocessing.OneHotEncoder(n_values=n_values)\n",
    "enc.fit(X)\n",
    "X_byte = enc.transform(X).toarray()\n",
    "\n",
    "X_byteDF = orig.makeDataFrame(X_byte,labels,n_values)\n",
    "result = pd.concat([X_byteDF, nonCategoryDF], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first_affiliate_tracked : nan\n",
      "first_browser : Opera Mobile\n",
      "first_browser : IBrowse\n",
      "first_browser : Nintendo Browser\n",
      "first_browser : CometBird\n",
      "first_browser : UC Browser\n",
      "language : -unknown-\n",
      "signup_method : weibo\n",
      "signup_flow : 14\n"
     ]
    }
   ],
   "source": [
    "myDrop = {}\n",
    "myList=('affiliate_channel', 'affiliate_provider', 'first_affiliate_tracked',\n",
    "        'first_browser', 'first_device_type', 'gender', 'language',\n",
    "        'signup_app', 'signup_method', 'signup_flow')\n",
    "for i in myList:\n",
    "    attrTest = getattr(usersTest,i)\n",
    "    attrTrain = getattr(usersTrain,i)\n",
    "    myDrop[i] = []\n",
    "    for x in attrTest.unique():\n",
    "        if x not in attrTrain.unique():\n",
    "            myDrop[i].append(x)\n",
    "            print(i,':', x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first_browser , Opera Mobile\n",
      "first_browser , IBrowse\n",
      "first_browser , Nintendo Browser\n",
      "first_browser , CometBird\n",
      "first_browser , UC Browser\n",
      "signup_flow , 14\n",
      "signup_method , weibo\n",
      "first_affiliate_tracked , nan\n",
      "language , -unknown-\n"
     ]
    }
   ],
   "source": [
    "for key in myDrop.keys():\n",
    "    for testCat in myDrop[key]:\n",
    "        print(key,',', testCat)\n",
    "        if pd.isnull(testCat): continue\n",
    "        myInd = myLabels[key].classes_.tolist().index(testCat)\n",
    "        label = key + '_' + str(myInd)\n",
    "        result = result.drop(label,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "orig.normDf(result)\n",
    "finalTrain = result[0:len(yRes)]\n",
    "finalTest = result[len(yRes):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "finalTrain.to_csv('../input_clean/users_train_final.csv')\n",
    "finalTest.to_csv('../input_clean/users_train_final.csv')\n",
    "yRes.to_csv('../input_clean/yRes_final.csv')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
